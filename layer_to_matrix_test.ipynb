{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3af1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as df\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import timm\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import easydict\n",
    "\n",
    "from transformers.models.bert.modeling_bert import BertSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c06b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters(module):\n",
    "    new_dict = {}\n",
    "    param_list = ['kernel_size', 'dilation', 'padding', 'stride']\n",
    "    for param in param_list:\n",
    "        new_dict[param] = module.__dict__[param]\n",
    "    return new_dict, module.weight.cpu().detach()\n",
    "class Hook_fwd():\n",
    "    def __init__(self, module):\n",
    "        self.module = module\n",
    "        self.hook = module.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.input =input\n",
    "        self.output = output\n",
    "    def close(self):\n",
    "        self.hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aa544d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b424c485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at gokuls/tiny-bert-sst2-1_mobilebert_and_bert-multi-teacher-distillation were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#model_name_list = ['bert-base-uncased']\n",
    "model_name_list = ['bert-base-uncased', 'gokuls/tiny-bert-sst2-1_mobilebert_and_bert-multi-teacher-distillation']\n",
    "for model_name in model_name_list:\n",
    "    try:\n",
    "        model = timm.create_model(model_name, pretrained=False)\n",
    "    except:\n",
    "        model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def compute_gemm_call(model, input_shape, batch_size, model_type, config):\n",
    "    forward_hook_list = []\n",
    "    for n, m in model.named_modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear) and 'attention' not in n:\n",
    "            if ('downsample' not in n) and ('shortcut' not in n):\n",
    "                print(n)\n",
    "                hook = Hook_fwd(m)\n",
    "                forward_hook_list.append([n, hook])\n",
    "        elif isinstance(m, BertSelfAttention):\n",
    "            # qkv calculate and compute self-attention \n",
    "            for nqkv, mqkv in m.named_modules():\n",
    "                if isinstance(mqkv, nn.Linear):\n",
    "                    print(nqkv)\n",
    "                    hook = Hook_fwd(mqkv)\n",
    "                    forward_hook_list.append([nqkv, hook])\n",
    "            print(n)\n",
    "            hook = Hook_fwd(m)\n",
    "            forward_hook_list.append([n, hook])            \n",
    "            \n",
    "        #elif 추 후 추가할 모델이 있으면 추가\n",
    "    \n",
    "    if model_type == 'nlp':\n",
    "        hidden_dim = config.hidden_size\n",
    "        dummy_input = torch.randn(batch_size, input_shape, hidden_dim).cuda()\n",
    "        print(\"nlp task's dummy input shape : \", dummy_input.shape)\n",
    "    \n",
    "    elif model_type == 'vision':\n",
    "        in_ch = 3\n",
    "        dummy_input = torch.randn(batch_size, in_ch, input_shape, input_shape).cuda()       \n",
    "        print(\"vision task's dummy input shape : \", dummy_input.shape)\n",
    "    \n",
    "    model = model.cuda()\n",
    "    out = model(dummy_input)\n",
    "    \n",
    "    out_strs = ''\n",
    "    if model_type in 'nlp':\n",
    "        for hook in forward_hook_list:\n",
    "            temp_module = hook[1].module\n",
    "            if isinstance(temp_module, BertSelfAttention):\n",
    "                inp_mat = hook[1].input[0]\n",
    "                attention_dict = temp_module.__dict__\n",
    "                num_head = attention_dict['num_attention_heads']\n",
    "                att_head_size = attention_dict['attention_head_size']\n",
    "                inp_shape = inp_mat.size()\n",
    "                assert num_head * att_head_size == inp_shape[2], f\"attention head ({num_head}) * head_dim ({att_head_size})  != embedding feature ({inp_shape[2]})\"\n",
    "                inp_reshape = inp_mat.reshape(inp_shape[0], inp_shape[1], num_head, att_head_size).permute(0,2,1,3).shape\n",
    "                \n",
    "                print(\"qk calculate\")\n",
    "\n",
    "                out_str = f'''\n",
    "=================================\n",
    "LayerName : attention_{hook[0]}_qk_compute\n",
    "IterN : {inp_reshape[0]*inp_reshape[1]} / ({inp_reshape[0], inp_reshape[1]})\n",
    "InputRow : {inp_reshape[2]}\n",
    "InputCol : {inp_reshape[3]}\n",
    "WeightRow : {inp_reshape[3]}\n",
    "WeightCol : {inp_reshape[2]}\n",
    "OutputRow : {inp_reshape[2]}\n",
    "OutputCol : {inp_reshape[2]}\n",
    "==================================\n",
    "                '''\n",
    "                \n",
    "                out_strs += out_str\n",
    "                \n",
    "                out_str = f'''\n",
    "=================================\n",
    "LayerName : attention_{hook[0]}_v_score_compute\n",
    "IterN : {inp_reshape[0]*inp_reshape[1]} / ({inp_reshape[0], inp_reshape[1]})\n",
    "InputRow : {inp_reshape[2]}\n",
    "InputCol : {inp_reshape[2]}\n",
    "WeightRow : {inp_reshape[2]}\n",
    "WeightCol : {inp_reshape[3]}\n",
    "OutputRow : {inp_reshape[2]}\n",
    "OutputCol : {inp_reshape[3]}\n",
    "==================================\n",
    "                    '''\n",
    "                out_strs += out_str                \n",
    "                \n",
    "            elif isinstance(temp_module, nn.Linear):\n",
    "                w_mat = temp_module.weight\n",
    "                inp_mat = hook[1].input[0]\n",
    "                print(inp_mat.size())\n",
    "                print(w_mat.size())\n",
    "                if len(inp_mat.size()) == 3:\n",
    "                    assert inp_mat.size(2) == w_mat.size(1), f\"required matmul input (m, n, k) * weight (k, o) but input {inp_mat.size()} != weight {w_mat.size()}\"\n",
    "                    out_str = f'''\n",
    "=================================\n",
    "LayerName : {hook[0]}\n",
    "IterN : {inp_mat.size()[0]}\n",
    "InputRow : {inp_mat.size()[1]}\n",
    "InputCol : {inp_mat.size()[2]}\n",
    "WeightRow : {w_mat.size()[1]}\n",
    "WeightCol : {w_mat.size()[0]}\n",
    "OutputRow : {inp_mat.size()[1]}\n",
    "OutputCol : {w_mat.size()[0]}\n",
    "==================================\n",
    "                    '''\n",
    "                    out_strs += out_str\n",
    "                elif len(inp_mat.size()) == 2:\n",
    "                    assert inp_mat.size(1) == w_mat.size(1), f\"required matmul input (n, k) * weight (k, o) but input {inp_mat.size()} != weight {w_mat.size()}\"\n",
    "                    out_str = f'''\n",
    "=================================\n",
    "LayerName : {hook[0]}\n",
    "InputRow : {inp_mat.size()[0]}\n",
    "InputCol : {inp_mat.size()[1]}\n",
    "WeightRow : {w_mat.size()[1]}\n",
    "WeightCol : {w_mat.size()[0]}\n",
    "OutputRow : {inp_mat.size()[0]}\n",
    "OutputCol : {w_mat.size()[0]}\n",
    "==================================\n",
    "                    '''\n",
    "                    out_strs += out_str \n",
    "    elif model_type == 'vision':\n",
    "        for hook in forward_hook_list:\n",
    "            temp_module = hook[1].module\n",
    "            if isinstance(temp_module, nn.Conv2d):\n",
    "                param_dict, conv_weight = get_parameters(temp_module)\n",
    "                input_tensor = hook[1].input[0]\n",
    "                inp_mat = F.unfold(input_tensor, **param_dict)\n",
    "                inp_mat = inp_mat.transpose(1,2).reshape(-1, inp_mat.size(1)) # inp_mat size\n",
    "                w_mat = conv_weight.reshape(conv_weight.size(0), -1).T\n",
    "                assert inp_mat.size(1) == w_mat.size(0), f\"required matmul input (m, k) * weight (k, n), but input {inp_mat.size()} != weight {w_mat.size()}\"\n",
    "                out_str = f'''\n",
    "=================================\n",
    "LayerName : {hook[0]}\n",
    "InputRow : {inp_mat.size()[0]}\n",
    "InputCol : {inp_mat.size()[1]}\n",
    "WeightRow : {w_mat.size()[0]}\n",
    "WeightCol : {w_mat.size()[1]}\n",
    "OutputRow : {inp_mat.size()[0]}\n",
    "OutputCol : {w_mat.size()[1]}\n",
    "==================================\n",
    "                '''\n",
    "                out_strs += out_str\n",
    "            elif isinstance(temp_module, nn.Linear):\n",
    "                w_mat = temp_module.weight\n",
    "                inp_mat = hook[1].input[0]\n",
    "                print(inp_mat.size())\n",
    "                print(w_mat.size())\n",
    "                assert inp_mat.size(1) == w_mat.size(1), f\"required matmul input (m, k) * weight (k, m) but input {inp_mat.size()} != weight {w_mat.size()}\"\n",
    "                out_str = f'''\n",
    "=================================\n",
    "LayerName : {hook[0]}\n",
    "InputRow : {inp_mat.size()[0]}\n",
    "InputCol : {inp_mat.size()[1]}\n",
    "WeightRow : {w_mat.size()[1]}\n",
    "WeightCol : {w_mat.size()[0]}\n",
    "OutputRow : {inp_mat.size()[0]}\n",
    "OutputCol : {w_mat.size()[0]}\n",
    "==================================\n",
    "                '''\n",
    "                out_strs += out_str\n",
    "            \n",
    "            \n",
    "    print(out_strs)\n",
    "    \n",
    "    out_txt_path = f'{model_name}_summary.txt'\n",
    "    if \"/\" in out_txt_path:\n",
    "        out_txt_path = out_txt_path.split(\"/\")[-1]\n",
    "\n",
    "    with open(f'./{out_txt_path}', \"w+\") as f:\n",
    "        f.write(out_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b8c12fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d956b6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query\n",
      "key\n",
      "value\n",
      "encoder.layer.0.attention.self\n",
      "encoder.layer.0.intermediate.dense\n",
      "encoder.layer.0.output.dense\n",
      "query\n",
      "key\n",
      "value\n",
      "encoder.layer.1.attention.self\n",
      "encoder.layer.1.intermediate.dense\n",
      "encoder.layer.1.output.dense\n",
      "pooler.dense\n",
      "nlp task's dummy input shape :  torch.Size([10, 100, 768])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m config_test \u001b[39m=\u001b[39m easydict\u001b[39m.\u001b[39mEasyDict()\n\u001b[1;32m      2\u001b[0m config_test\u001b[39m.\u001b[39mhidden_size \u001b[39m=\u001b[39m\u001b[39m768\u001b[39m\n\u001b[0;32m----> 4\u001b[0m compute_gemm_call(model, input_shape\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, model_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnlp\u001b[39;49m\u001b[39m'\u001b[39;49m, config\u001b[39m=\u001b[39;49mconfig_test)\n",
      "Cell \u001b[0;32mIn [6], line 41\u001b[0m, in \u001b[0;36mcompute_gemm_call\u001b[0;34m(model, input_shape, batch_size, model_type, config)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mvision task\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms dummy input shape : \u001b[39m\u001b[39m\"\u001b[39m, dummy_input\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     40\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 41\u001b[0m model(dummy_input)\n\u001b[1;32m     43\u001b[0m out_strs \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mnlp\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1184\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1185\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1186\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py:968\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 968\u001b[0m batch_size, seq_length \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m    969\u001b[0m device \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mdevice \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m inputs_embeds\u001b[39m.\u001b[39mdevice\n\u001b[1;32m    971\u001b[0m \u001b[39m# past_key_values_length\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "config_test = easydict.EasyDict()\n",
    "config_test.hidden_size =768\n",
    "\n",
    "compute_gemm_call(model, input_shape=100, batch_size=10, model_type='nlp', config=config_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526430a3",
   "metadata": {},
   "source": [
    "### 구현 남은 것\n",
    "\n",
    "#### Depthwise Convolution 구현 어떻게 해야하는 지 (and group size convolution 어떻게 계산할지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f603d06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
